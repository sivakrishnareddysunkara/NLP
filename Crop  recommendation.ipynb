{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas_profiling\n",
      "  Using cached pandas_profiling-2.11.0-py2.py3-none-any.whl (243 kB)\n",
      "Requirement already satisfied, skipping upgrade: htmlmin>=0.1.12 in c:\\python39\\lib\\site-packages (from pandas_profiling) (0.1.12)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.48.2 in c:\\python39\\lib\\site-packages (from pandas_profiling) (4.56.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib in c:\\python39\\lib\\site-packages (from pandas_profiling) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.16.0 in c:\\python39\\lib\\site-packages (from pandas_profiling) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: seaborn>=0.10.1 in c:\\python39\\lib\\site-packages (from pandas_profiling) (0.11.1)\n",
      "Requirement already satisfied, skipping upgrade: phik>=0.10.0 in c:\\python39\\lib\\site-packages (from pandas_profiling) (0.11.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.4.1 in c:\\python39\\lib\\site-packages (from pandas_profiling) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.24.0 in c:\\python39\\lib\\site-packages (from pandas_profiling) (2.25.1)\n",
      "Requirement already satisfied, skipping upgrade: missingno>=0.4.2 in c:\\python39\\lib\\site-packages (from pandas_profiling) (0.4.2)\n",
      "Collecting ipywidgets>=7.5.1\n",
      "  Using cached ipywidgets-7.6.3-py2.py3-none-any.whl (121 kB)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib>=3.2.0 in c:\\python39\\lib\\site-packages (from pandas_profiling) (3.3.4)\n",
      "Requirement already satisfied, skipping upgrade: tangled-up-in-unicode>=0.0.6 in c:\\python39\\lib\\site-packages (from pandas_profiling) (0.0.7)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=19.3.0 in c:\\python39\\lib\\site-packages (from pandas_profiling) (20.3.0)\n",
      "Requirement already satisfied, skipping upgrade: visions[type_image_path]==0.6.0 in c:\\python39\\lib\\site-packages (from pandas_profiling) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in c:\\python39\\lib\\site-packages (from pandas_profiling) (1.2.3)\n",
      "Requirement already satisfied, skipping upgrade: confuse>=1.0.0 in c:\\python39\\lib\\site-packages (from pandas_profiling) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: jinja2>=2.11.1 in c:\\python39\\lib\\site-packages (from pandas_profiling) (2.11.3)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in c:\\python39\\lib\\site-packages (from requests>=2.24.0->pandas_profiling) (1.26.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\python39\\lib\\site-packages (from requests>=2.24.0->pandas_profiling) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\python39\\lib\\site-packages (from requests>=2.24.0->pandas_profiling) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: chardet<5,>=3.0.2 in c:\\python39\\lib\\site-packages (from requests>=2.24.0->pandas_profiling) (4.0.0)\n",
      "Collecting jupyterlab-widgets>=1.0.0; python_version >= \"3.6\"\n",
      "  Using cached jupyterlab_widgets-1.0.0-py3-none-any.whl (243 kB)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.3.1 in c:\\python39\\lib\\site-packages (from ipywidgets>=7.5.1->pandas_profiling) (5.0.5)\n",
      "Collecting nbformat>=4.2.0\n",
      "  Using cached nbformat-5.1.2-py3-none-any.whl (113 kB)\n",
      "Requirement already satisfied, skipping upgrade: ipython>=4.0.0; python_version >= \"3.3\" in c:\\python39\\lib\\site-packages (from ipywidgets>=7.5.1->pandas_profiling) (7.22.0)\n",
      "Collecting widgetsnbextension~=3.5.0\n",
      "  Using cached widgetsnbextension-3.5.1-py2.py3-none-any.whl (2.2 MB)\n",
      "Collecting ipykernel>=4.5.1\n",
      "  Using cached ipykernel-5.5.0-py3-none-any.whl (120 kB)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in c:\\python39\\lib\\site-packages (from matplotlib>=3.2.0->pandas_profiling) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in c:\\python39\\lib\\site-packages (from matplotlib>=3.2.0->pandas_profiling) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in c:\\python39\\lib\\site-packages (from matplotlib>=3.2.0->pandas_profiling) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\python39\\lib\\site-packages (from matplotlib>=3.2.0->pandas_profiling) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in c:\\python39\\lib\\site-packages (from matplotlib>=3.2.0->pandas_profiling) (8.1.2)\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.4 in c:\\python39\\lib\\site-packages (from visions[type_image_path]==0.6.0->pandas_profiling) (2.5)\n",
      "Requirement already satisfied, skipping upgrade: imagehash; extra == \"type_image_path\" in c:\\python39\\lib\\site-packages (from visions[type_image_path]==0.6.0->pandas_profiling) (4.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in c:\\python39\\lib\\site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas_profiling) (2021.1)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in c:\\python39\\lib\\site-packages (from confuse>=1.0.0->pandas_profiling) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in c:\\python39\\lib\\site-packages (from jinja2>=2.11.1->pandas_profiling) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in c:\\python39\\lib\\site-packages (from traitlets>=4.3.1->ipywidgets>=7.5.1->pandas_profiling) (0.2.0)\n",
      "Collecting jsonschema!=2.5.0,>=2.4\n",
      "  Using cached jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-core in c:\\python39\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->pandas_profiling) (4.7.1)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in c:\\python39\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas_profiling) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: decorator in c:\\python39\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas_profiling) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: pygments in c:\\python39\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas_profiling) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.16 in c:\\python39\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas_profiling) (0.18.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in c:\\python39\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas_profiling) (49.2.1)\n",
      "Requirement already satisfied, skipping upgrade: backcall in c:\\python39\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas_profiling) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: colorama; sys_platform == \"win32\" in c:\\python39\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas_profiling) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\python39\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas_profiling) (3.0.18)\n",
      "Collecting notebook>=4.4.1\n",
      "  Using cached notebook-6.3.0-py3-none-any.whl (9.5 MB)\n",
      "Collecting jupyter-client\n",
      "  Using cached jupyter_client-6.1.12-py3-none-any.whl (112 kB)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=4.2 in c:\\python39\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas_profiling) (6.1)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\python39\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.2.0->pandas_profiling) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: PyWavelets in c:\\python39\\lib\\site-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.6.0->pandas_profiling) (1.1.1)\n",
      "Collecting pyrsistent>=0.14.0\n",
      "  Using cached pyrsistent-0.17.3.tar.gz (106 kB)\n",
      "Requirement already satisfied, skipping upgrade: pywin32>=1.0; sys_platform == \"win32\" in c:\\python39\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets>=7.5.1->pandas_profiling) (300)\n",
      "Requirement already satisfied, skipping upgrade: parso<0.9.0,>=0.8.0 in c:\\python39\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas_profiling) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in c:\\python39\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas_profiling) (0.2.5)\n",
      "Collecting nbconvert\n",
      "  Using cached nbconvert-6.0.7-py3-none-any.whl (552 kB)\n",
      "Collecting Send2Trash>=1.5.0\n",
      "  Using cached Send2Trash-1.5.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=17 in c:\\python39\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas_profiling) (22.0.3)\n",
      "Collecting argon2-cffi\n",
      "  Using cached argon2_cffi-20.1.0-cp39-cp39-win_amd64.whl (42 kB)\n",
      "Collecting prometheus-client\n",
      "  Using cached prometheus_client-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting terminado>=0.8.3\n",
      "  Using cached terminado-0.9.3-py3-none-any.whl (14 kB)\n",
      "Collecting defusedxml\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Using cached jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\n",
      "Collecting testpath\n",
      "  Using cached testpath-0.4.4-py2.py3-none-any.whl (163 kB)\n",
      "Collecting mistune<2,>=0.8.1\n",
      "  Using cached mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Using cached pandocfilters-1.4.3.tar.gz (16 kB)\n",
      "Collecting entrypoints>=0.2.2\n",
      "  Using cached entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Collecting bleach\n",
      "  Using cached bleach-3.3.0-py2.py3-none-any.whl (283 kB)\n",
      "Collecting nbclient<0.6.0,>=0.5.0\n",
      "  Using cached nbclient-0.5.3-py3-none-any.whl (82 kB)\n",
      "Requirement already satisfied, skipping upgrade: cffi>=1.0.0 in c:\\python39\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas_profiling) (1.14.5)\n",
      "Collecting pywinpty>=0.5; os_name == \"nt\"\n",
      "  Using cached pywinpty-0.5.7.tar.gz (49 kB)\n",
      "Collecting webencodings\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied, skipping upgrade: packaging in c:\\python39\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas_profiling) (20.8)\n",
      "Requirement already satisfied, skipping upgrade: nest-asyncio in c:\\python39\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas_profiling) (1.5.1)\n",
      "Collecting async-generator\n",
      "  Using cached async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in c:\\python39\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas_profiling) (2.20)\n",
      "Using legacy 'setup.py install' for pyrsistent, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for pandocfilters, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for pywinpty, since package 'wheel' is not installed.\n",
      "Installing collected packages: jupyterlab-widgets, pyrsistent, jsonschema, nbformat, defusedxml, jupyterlab-pygments, testpath, mistune, pandocfilters, entrypoints, webencodings, bleach, jupyter-client, async-generator, nbclient, nbconvert, Send2Trash, ipykernel, argon2-cffi, prometheus-client, pywinpty, terminado, notebook, widgetsnbextension, ipywidgets, pandas-profiling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\python39\\\\share'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Using cached plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n",
      "Collecting retrying>=1.3.3\n",
      "  Using cached retrying-1.3.3.tar.gz (10 kB)\n",
      "Requirement already satisfied: six in c:\\python39\\lib\\site-packages (from plotly) (1.15.0)\n",
      "Using legacy 'setup.py install' for retrying, since package 'wheel' is not installed.\n",
      "Installing collected packages: retrying, plotly\n",
      "    Running setup.py install for retrying: started\n",
      "    Running setup.py install for retrying: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'c:\\python39\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\sivakrishna.sunkara\\\\AppData\\\\Local\\\\Temp\\\\pip-install-zrn614n0\\\\retrying\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\sivakrishna.sunkara\\\\AppData\\\\Local\\\\Temp\\\\pip-install-zrn614n0\\\\retrying\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\sivakrishna.sunkara\\AppData\\Local\\Temp\\pip-record-qscjg7qc\\install-record.txt' --single-version-externally-managed --compile --install-headers 'c:\\python39\\Include\\retrying'\n",
      "         cwd: C:\\Users\\sivakrishna.sunkara\\AppData\\Local\\Temp\\pip-install-zrn614n0\\retrying\\\n",
      "    Complete output (9 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib\n",
      "    copying retrying.py -> build\\lib\n",
      "    running install_lib\n",
      "    byte-compiling c:\\python39\\Lib\\site-packages\\retrying.py to retrying.cpython-39.pyc\n",
      "    error: [Errno 13] Permission denied: 'c:\\\\python39\\\\Lib\\\\site-packages\\\\__pycache__\\\\retrying.cpython-39.pyc.2483592300464'\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'c:\\python39\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\sivakrishna.sunkara\\\\AppData\\\\Local\\\\Temp\\\\pip-install-zrn614n0\\\\retrying\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\sivakrishna.sunkara\\\\AppData\\\\Local\\\\Temp\\\\pip-install-zrn614n0\\\\retrying\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\sivakrishna.sunkara\\AppData\\Local\\Temp\\pip-record-qscjg7qc\\install-record.txt' --single-version-externally-managed --compile --install-headers 'c:\\python39\\Include\\retrying' Check the logs for full command output.\n",
      "WARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\python39\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\python39\\lib\\site-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python39\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.19.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pandas_profiling\n",
    "!pip install plotly\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-6d1877f715aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_profiling\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas_profiling'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import pickle\n",
    "from sklearn.utils import resample\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, auc, roc_curve\n",
    "\n",
    "# Validation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# Tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Feature Extraction\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, Binarizer, LabelEncoder\n",
    "\n",
    "# Models\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Ensembles\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "\n",
    "# Analyze Data\n",
    "def explore_data(df):\n",
    "    print(\"Number of Instances and Attributes:\", df.shape)\n",
    "    print('\\n')\n",
    "    print('Dataset columns:',df.columns)\n",
    "    print('\\n')\n",
    "    print('Data types of each columns: ', df.info())\n",
    "    \n",
    "# Checking for duplicates\n",
    "def checking_removing_duplicates(df):\n",
    "    count_dups = df.duplicated().sum()\n",
    "    print(\"Number of Duplicates: \", count_dups)\n",
    "    if count_dups >= 1:\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        print('Duplicate values removed!')\n",
    "    else:\n",
    "        print('No Duplicate values')\n",
    "    \n",
    "\n",
    "# Split training and validation set\n",
    "def read_in_and_split_data(data, target):\n",
    "    X = data.drop(target, axis=1)\n",
    "    y = data[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "# Spot-Check Algorithms\n",
    "def GetModel():\n",
    "    Models = []\n",
    "    Models.append(('LR'   , LogisticRegression()))\n",
    "    Models.append(('LDA'  , LinearDiscriminantAnalysis()))\n",
    "    Models.append(('KNN'  , KNeighborsClassifier()))\n",
    "    Models.append(('CART' , DecisionTreeClassifier()))\n",
    "    Models.append(('NB'   , GaussianNB()))\n",
    "    Models.append(('SVM'  , SVC(probability=True)))\n",
    "    return Models\n",
    "\n",
    "def ensemblemodels():\n",
    "    ensembles = []\n",
    "    ensembles.append(('AB'   , AdaBoostClassifier()))\n",
    "    ensembles.append(('GBM'  , GradientBoostingClassifier()))\n",
    "    ensembles.append(('RF'   , RandomForestClassifier()))\n",
    "    ensembles.append(( 'Bagging' , BaggingClassifier()))\n",
    "    ensembles.append(('ET', ExtraTreesClassifier()))\n",
    "    return ensembles\n",
    "\n",
    "# Spot-Check Normalized Models\n",
    "def NormalizedModel(nameOfScaler):\n",
    "    \n",
    "    if nameOfScaler == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif nameOfScaler =='minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif nameOfScaler == 'normalizer':\n",
    "        scaler = Normalizer()\n",
    "    elif nameOfScaler == 'binarizer':\n",
    "        scaler = Binarizer()\n",
    "\n",
    "    pipelines = []\n",
    "    pipelines.append((nameOfScaler+'LR'  , Pipeline([('Scaler', scaler),('LR'  , LogisticRegression())])))\n",
    "    pipelines.append((nameOfScaler+'LDA' , Pipeline([('Scaler', scaler),('LDA' , LinearDiscriminantAnalysis())])))\n",
    "    pipelines.append((nameOfScaler+'KNN' , Pipeline([('Scaler', scaler),('KNN' , KNeighborsClassifier())])))\n",
    "    pipelines.append((nameOfScaler+'CART', Pipeline([('Scaler', scaler),('CART', DecisionTreeClassifier())])))\n",
    "    pipelines.append((nameOfScaler+'NB'  , Pipeline([('Scaler', scaler),('NB'  , GaussianNB())])))\n",
    "    pipelines.append((nameOfScaler+'SVM' , Pipeline([('Scaler', scaler),('SVM' , SVC())])))\n",
    "    pipelines.append((nameOfScaler+'AB'  , Pipeline([('Scaler', scaler),('AB'  , AdaBoostClassifier())])  ))\n",
    "    pipelines.append((nameOfScaler+'GBM' , Pipeline([('Scaler', scaler),('GMB' , GradientBoostingClassifier())])  ))\n",
    "    pipelines.append((nameOfScaler+'RF'  , Pipeline([('Scaler', scaler),('RF'  , RandomForestClassifier())])  ))\n",
    "    pipelines.append((nameOfScaler+'ET'  , Pipeline([('Scaler', scaler),('ET'  , ExtraTreesClassifier())])  ))\n",
    "\n",
    "    return pipelines\n",
    "\n",
    "# Train model\n",
    "def fit_model(X_train, y_train,models):\n",
    "    # Test options and evaluation metric\n",
    "    num_folds = 10\n",
    "    scoring = 'accuracy'\n",
    "\n",
    "    results = []\n",
    "    names = []\n",
    "    for name, model in models:\n",
    "        kfold = KFold(n_splits=num_folds, shuffle=True, random_state=0)\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "        \n",
    "    return names, results\n",
    "\n",
    "# Save trained model\n",
    "def save_model(model,filename):\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# Performance Measure\n",
    "def classification_metrics(model, conf_matrix):\n",
    "    print(f\"Training Accuracy Score: {model.score(X_train, y_train) * 100:.1f}%\")\n",
    "    print(f\"Validation Accuracy Score: {model.score(X_test, y_test) * 100:.1f}%\")\n",
    "    fig,ax = plt.subplots(figsize=(8,6))\n",
    "    sns.heatmap(pd.DataFrame(conf_matrix), annot = True, cmap = 'YlGnBu',fmt = 'g')\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    plt.tight_layout()\n",
    "    plt.title('Confusion Matrix', fontsize=20, y=1.1)\n",
    "    plt.ylabel('Actual label', fontsize=15)\n",
    "    plt.xlabel('Predicted label', fontsize=15)\n",
    "    plt.show()\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "# ROC_AUC\n",
    "def roc_auc(y_test, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    print(f\"roc_auc score: {auc(fpr, tpr)*100:.1f}%\")\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate',fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=20)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File Crop_recommendation.csv does not exist: 'Crop_recommendation.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1ea8a0fbce7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Crop_recommendation.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File Crop_recommendation.csv does not exist: 'Crop_recommendation.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Crop_recommendation.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checking_removing_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns contain outliers except for rice and label you can check outliers by using boxplot\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df_out = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target ='label'\n",
    "X_train, X_test, y_train, y_test = read_in_and_split_data(df, target)\n",
    "\n",
    "models = GetModel()\n",
    "names,results = fit_model(X_train, y_train,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScaledModel = NormalizedModel('minmax')\n",
    "name,results = fit_model(X_train, y_train, ScaledModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScaledModel = NormalizedModel('standard')\n",
    "name,results = fit_model(X_train, y_train, ScaledModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScaledModel = NormalizedModel('normalizer')\n",
    "name,results = fit_model(X_train, y_train, ScaledModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(MinMaxScaler(),  GaussianNB())\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "classification_metrics(pipeline, conf_matrix)\n",
    "\n",
    "# save model\n",
    "save_model(model, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 40\n",
    "P = 50\n",
    "K = 60\n",
    "temperature = 12.82312\n",
    "humidity = 82.00284\n",
    "ph = 6.50232\n",
    "rainfall = 20.93536\n",
    "\n",
    "sample = [N, P, K, temperature, humidity, ph, rainfall]\n",
    "single_sample = np.array(sample).reshape(1,-1)\n",
    "pred = model.predict(single_sample)\n",
    "pred.item().title()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
